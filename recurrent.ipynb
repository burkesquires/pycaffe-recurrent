{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Recurrent Network for Character Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from caffe import *\n",
    "from caffe.proto.caffe_pb2 import *\n",
    "Lr, Pr = layers, params\n",
    "import string, os, h5py, json\n",
    "from glob import glob\n",
    "sf = lambda *x: string.join([str(i) for i in x], '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Specify Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hypes = {\n",
    "    'sequence_length': 100,\n",
    "    'layers_num': 2,\n",
    "    'state_dim': 256,\n",
    "    'batch_size': 64,\n",
    "    'recurrent_unit': 'lstm', # rnn or lstm\n",
    "    'solver': {\n",
    "        'base_lr': 5e-3,\n",
    "        'weight_decay': 1e-4,\n",
    "        'lr_policy': 'exp',\n",
    "        'gamma': 0.9999,\n",
    "        'clip_gradients': 100,\n",
    "        'solver_type': SolverParameter.RMSPROP,\n",
    "        'rms_decay': 0.8\n",
    "    }\n",
    "}\n",
    "\n",
    "txt_file = 'rawtxt/linux_kernel.txt'\n",
    "use_gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = hypes['sequence_length']\n",
    "L = hypes['layers_num']\n",
    "d = hypes['state_dim']\n",
    "b = hypes['batch_size']\n",
    "\n",
    "json.dump(hypes, open('hypes.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txt = open(txt_file, 'r').read()\n",
    "C = sorted(set(txt))\n",
    "k = len(C)\n",
    "if k <= 2**8: uintn = uint8\n",
    "else: uintn = uint16\n",
    "X = array([C.index(c) for c in txt], dtype=uintn)\n",
    "Y = X[1:].copy()\n",
    "X = X[:-1]\n",
    "\n",
    "def chop(x, n=None, m=None):\n",
    "    if n: m = len(x)//n\n",
    "    if m: n = len(x)//m\n",
    "    X = split(array(x[:m*n]), n)\n",
    "    return array(X)\n",
    "\n",
    "rshape = lambda A: chop(rollaxis(chop(A,n=b),1,0),m=T)\n",
    "X, Y = map(rshape, [X, Y])\n",
    "\n",
    "data = h5py.File('data.h5', 'w')\n",
    "data.create_group('train')\n",
    "data.create_group('test')\n",
    "a = 9*len(X)/10\n",
    "data['train']['X'] = X[:a]\n",
    "data['train']['Y'] = Y[:a]\n",
    "data['test']['X'] = X[a:]\n",
    "data['test']['Y'] = Y[a:]\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_step(h, h_below, kwargs_fc):\n",
    "    \n",
    "    kwargs_fc['num_output'] = d\n",
    "    \n",
    "    h = Lr.Concat(h_below, h)\n",
    "    h = Lr.InnerProduct(h, **kwargs_fc)\n",
    "    h = Lr.TanH(h)\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lstm_step(h, h_below, kwargs_fc):\n",
    "    \n",
    "    kwargs_fc['num_output'] = 2*d\n",
    "    \n",
    "    PROD = EltwiseParameter.PROD\n",
    "    c, h = Lr.Slice(h, slice_point=d/2, ntop=2)\n",
    "    h = Lr.Concat(h_below, h)\n",
    "    h = Lr.InnerProduct(h, **kwargs_fc)\n",
    "    i, f, o, g = Lr.Slice(h, slice_point=[d/2,d,3*d/2], ntop=4)\n",
    "    i, f, o = map(Lr.Sigmoid, [i, f, o])\n",
    "    g = Lr.TanH(g)\n",
    "    c = Lr.Eltwise(Lr.Eltwise(f, c, operation=PROD), Lr.Eltwise(i, g, operation=PROD))\n",
    "    h = Lr.Eltwise(o, Lr.TanH(c), operation=PROD)\n",
    "    h = Lr.Concat(c, h)\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_net_param(T, b, drop=True):\n",
    "    \n",
    "    net_spec = NetSpec()\n",
    "\n",
    "    bsX, bsY, bsH = [BlobShape() for i in range(3)]\n",
    "    bsH.dim.extend([b,d])\n",
    "    bsX.dim.extend([b,k])\n",
    "    bsY.dim.extend([b])\n",
    "\n",
    "    if hypes['recurrent_unit'] == 'rnn': step = rnn_step\n",
    "    if hypes['recurrent_unit'] == 'lstm': step = lstm_step\n",
    "    \n",
    "    get_kwargs_fc = lambda t, l: {\n",
    "        'param': [{'lr_mult': 1, 'decay_mult': 1, 'name': sf('W', l)},\n",
    "                  {'lr_mult': 2, 'decay_mult': 0, 'name': sf('b', l)}],\n",
    "        'weight_filler': {'type': 'uniform', 'min': -0.01, 'max': 0.01},\n",
    "        'name': sf('fc', t, l)\n",
    "    }\n",
    "    \n",
    "    h = []\n",
    "    for l in range(L):\n",
    "        h.append(Lr.DummyData(shape=bsH))\n",
    "        setattr(net_spec, sf('h',0,l), h[l])\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for t in range(T):\n",
    "\n",
    "        x = Lr.DummyData(shape=bsX)\n",
    "        y = Lr.DummyData(shape=bsY)\n",
    "\n",
    "        h[0] = step(h[0], x, get_kwargs_fc(t, 0))\n",
    "        for l in range(1, L):\n",
    "            h[l] = step(h[l], h[l-1], get_kwargs_fc(t, l))\n",
    "            if drop: h[l] = Lr.Dropout(h[l])\n",
    "\n",
    "        kwargs_fc = get_kwargs_fc(t, L)\n",
    "        kwargs_fc['num_output'] = k\n",
    "        \n",
    "        z = Lr.InnerProduct(h[-1], **kwargs_fc)\n",
    "        loss = Lr.SoftmaxWithLoss(z, y)\n",
    "        \n",
    "        setattr(net_spec, sf('x', t), x)\n",
    "        setattr(net_spec, sf('y', t), y)\n",
    "        setattr(net_spec, sf('z', t), z)\n",
    "        for l in range(L): \n",
    "            setattr(net_spec, sf('h', t+1, l), h[l])\n",
    "        setattr(net_spec, sf('loss', t), loss)\n",
    "    \n",
    "    return net_spec.to_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver_hypes = hypes['solver']\n",
    "\n",
    "if use_gpu:\n",
    "    solver_hypes['solver_mode'] = SolverParameter.GPU\n",
    "    solver_hypes['device_id'] = 0\n",
    "else:\n",
    "    solver_hypes['solver_mode'] = SolverParameter.CPU\n",
    "\n",
    "solver_param = SolverParameter()\n",
    "solver_param.net_param.CopyFrom(get_net_param(T, b))\n",
    "solver_param.test_net_param.add()\n",
    "solver_param.test_net_param[0].CopyFrom(get_net_param(T, b, drop=False))\n",
    "solver_param.test_iter.extend([1])\n",
    "solver_param.test_interval = 10**9\n",
    "for pr, val in solver_hypes.iteritems():\n",
    "    setattr(solver_param, pr, val)\n",
    "\n",
    "with open('solver.prototxt', 'w') as f: f.write(str(solver_param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Better to run this from the command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Deploy (run this while training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed_chars = '#inc'\n",
    "temperature = 0.7\n",
    "num_chars = 1000\n",
    "\n",
    "open('deploy.prototxt', 'w').write(str(get_net_param(1, 1, drop=False)))\n",
    "net = Net('deploy.prototxt', 1)\n",
    "\n",
    "def load_params(net, params_file):\n",
    "    param_corresp = [(sf('fc',l), sf('fc',0,l)) for l in range(L+1)]\n",
    "    params_file = sorted(glob('params/iter*.h5'))[-2]\n",
    "    params = h5py.File(params_file, 'r')\n",
    "    for ki, kj in param_corresp:\n",
    "        pr = net.params[kj]\n",
    "        pr[0].data[...] = params[ki]['W'].value\n",
    "        pr[1].data[...] = params[ki]['b'].value\n",
    "\n",
    "params_file = sorted(glob('params/iter*.h5'))[-2]\n",
    "load_params(net, params_file)\n",
    "        \n",
    "for c in seed_chars:\n",
    "    x = C.index(c)\n",
    "    net.blobs[sf('x',0)].data[...] = 0\n",
    "    net.blobs[sf('x',0)].data[0, x] = 1\n",
    "    for l in range(L):\n",
    "        state_i = net.blobs[sf('h',0,l)].data\n",
    "        state_f = net.blobs[sf('h',1,l)].data\n",
    "        state_i[...] = state_f\n",
    "    net.forward()\n",
    "\n",
    "gen_chars = []\n",
    "for t in range(num_chars):\n",
    "    z = net.blobs[sf('z',0)].data[0].copy().astype(float)\n",
    "    p = (lambda x: x/sum(x))(exp(z/temperature))\n",
    "    x = random.choice(range(k), p=p)\n",
    "    gen_chars.append(C[x])\n",
    "    net.blobs[sf('x',0)].data[...] = 0\n",
    "    net.blobs[sf('x',0)].data[0, x] = 1\n",
    "    for l in range(L):\n",
    "        state_i = net.blobs[sf('h',0,l)].data\n",
    "        state_f = net.blobs[sf('h',1,l)].data\n",
    "        state_i[...] = state_f\n",
    "    net.forward()\n",
    "            \n",
    "print seed_chars + string.join(gen_chars, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
